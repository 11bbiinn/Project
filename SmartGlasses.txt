#!/usr/bin/python
# -*- coding:utf-8 -*-

import sys
import os
picdir = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), 'pic')
libdir = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), 'lib')
if os.path.exists(libdir):
    sys.path.append(libdir)

import logging    
import time
import traceback
from waveshare_OLED import OLED_1in51
from PIL import Image,ImageDraw,ImageFont
logging.basicConfig(level=logging.DEBUG)

import time
import picamera
from pytesseract import Output
import pytesseract
import cv2
try:
   import Image
except ImportError:
   from PIL import Image
import urllib.request
import json
import re

def wrap_text(text, text_len): #한글 문자열 길이 나누는 함수
    result = ""
    length = 0
    
    if(text_len >= 40):
         max_length = 24
        
    elif(text_len < 40 and text_len > 10):
         max_length = 20

    else:
         max_length = 13
            
    for char in text:
        result += char
        length += 1
        if ord(char) >= 0xAC00 and ord(char) <= 0xD7AF:   # 한글 유니코드 범위: AC00-D7AF
            length += 1  # 한글은 2바이트로 계산
        if length >= max_length:
            result += "\n"
            length = 0
    return result



def OLED(text, text_len):
    try:
        disp = OLED_1in51.OLED_1in51()

        disp.Init()     # Initialize library.
        disp.clear()    # Clear display.

        # Create blank image for drawing.
        image1 = Image.new('1', (disp.width, disp.height), "WHITE")
        draw = ImageDraw.Draw(image1)
        font1 = ImageFont.truetype(os.path.join(picdir, 'Font.ttc'), 9)
        font2 = ImageFont.truetype(os.path.join(picdir, 'Font.ttc'), 12)
        font3 = ImageFont.truetype(os.path.join(picdir, 'Font.ttc'), 14)
        
        if(text_len >= 40):
             draw.text((2,4), text, font = font1, fill = 0)
        
        elif(text_len < 40 and text_len > 10):
             draw.text((2,4), text, font = font2, fill = 0)

        else:
            draw.text((2,4), text, font = font3, fill = 0)
            
        image1 = image1.rotate(360) 
        disp.ShowImage(disp.getbuffer(image1))
        time.sleep(10)
    
    except IOError as e:
        logging.info(e)
    
    except KeyboardInterrupt:    
        logging.info("ctrl + c:")
        OLED_1in51.config.module_exit()
        exit()


def translate(text): #번역하는 함수

    client_id = "cxVrUPqOthxoZJA6U4LD"

    client_secret = "IQvaRZJuQ1"

    encText = urllib.parse.quote(text)

    data = "source=en&target=ko&text=" + encText

    url = "https://openapi.naver.com/v1/papago/n2mt"

    request = urllib.request.Request(url)

    request.add_header("X-Naver-Client-Id",client_id)

    request.add_header("X-Naver-Client-Secret",client_secret)

    response = urllib.request.urlopen(request, data=data.encode("utf-8"))

    rescode = response.getcode()

    if(rescode==200):

        response_body = response.read()

        result=response_body.decode('utf-8')

        d=json.loads(result)

        #print(d['message']['result']['translatedText'])
        text = d['message']['result']['translatedText']
        text = re.sub(r'[^가-힣\s]', '', text) #한글을 제외한 글자 제거
        
        text_len = len(text)
        
        print(text) ##############################
        
        last_text = wrap_text(text, text_len)
        OLED(last_text, text_len)

    else:

        print("Error Code:" + rescode)


# 카메라 초기화
camera = picamera.PiCamera()

camera.resolution = (640, 480)  # 이미지 해상도 설정
#camera()


#def camera(): #카메라 찍는 함수
    
while True:
        # 현재 시간을 이용한 파일 이름 생성
    file_name = "text_cam.jpg"

        # 사진 찍기
    camera.rotation = 180
    camera.capture(file_name)

    image = cv2.imread(file_name)
    flipped_image = cv2.flip(image, 1)  # 두 번째 인자로 0이면 수직 뒤집기, 1이면 수평 뒤집기

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #이미지 전처리
    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1] #이미지 전처리
    gray = cv2.medianBlur(gray,1) #이미지에 노이즈 제거를 위한 미디안 블러 처리
    
    #cv2.imshow("gray",gray)
    #cv2.waitKey(0)
    
    text = pytesseract.image_to_string(gray, lang='eng')

    processed_text = text.strip().replace('\n', ' ') # 추출된 텍스트 후처리
    
        # 인식된 텍스트 출력
    print("Recognized Text:")
    print(processed_text)

    processed_text = processed_text.replace(",", ",\n").replace(".", ".\n")
    
    if len(processed_text) >= 1:        
        translate(processed_text) #최종 텍스트 번역

        # 2초 대기
    time.sleep(1)
